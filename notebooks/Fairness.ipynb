{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Fairness\n",
    "\n",
    "Hold on to your data scientist hat but make room for your tester hat.  You'll need both for this section on AI/ML fairness. In these lessons, you are going to learn how to assess ML models for fairness so that you can identify and quantify fairness-related risks, and employ various strategies to mitigate them.  Since testing is about risk and risk mitigation, the AI/ML and software testing worlds intersect quite naturally here as part of this holistic quality engineering strategy for ML systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction to AI Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "AI is everywhere and in many ways this is great. However, at the same time, the opportunities brought about by AI also raise new challenges. Some of these challenges have received much attention in the media, and have highlighted the need to \"get AI right\".  Fairness in AI is about making sure that machines do not discriminate against certain groups of people, and possibly place already disadvantaged groups at a further disadvantage.  AI fairness is a fundamentally sociotechnical challenge, meaning that it cannot be approached from purely social or purely technical perspectives. Taken together, these factors can make it a pretty daunting landscape to navigate. Although there are few easy answers, there are a variety of strategies emerging for assessing and mitigating fairness-related risks, as well as a deepening understanding of the challenge throughout society. This tutorial explores these issues and gives you practice using open-source fairness toolkits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/fairnessnotlaw.png\" width=\"250\">\n",
    "\n",
    "### Fairness Not Law\n",
    "\n",
    "Fairness is related, but distinct from anti-discrimination law. In this training, legal terminology like: _discriminate against_, _protected class_, _disparate treatment_ and _disparate impact_ are avoided. Although fairness is related to the concepts in anti-discrimination law, the goal is to focus on fairness and not touch on the legal considerations. It is important to note that some fairness interventions could be illegal, and, conversely, there are AI systems that follow the law, including antidiscrimination law, but still exhibit fairness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Impacts and Risks Instead of Bias\n",
    "\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/biasintersection.png\" width=\"200\">\n",
    "\n",
    "If you’ve read anything about fairness in AI systems then you’ve probably seen the word _bias_ get thrown around. In it's textbook definition, **bias** is a systemic or disproportionate tendency toward something or someone. When it comes to AI, bias is often used as a _catch-all_ phrase for describing any unfair system behavior, or causes of that unfairness. This training avoids using the word bias whenever possible because the term is ambiguous. Bias means very different things to different communities. For example, there is statistical bias, social bias, and systemic bias to name a few.  However, most issues typically arise at the intersection of different types of bias.  For this reason, it is better to talk about the **impacts** or **risks** related to fairness in AI-based systems. Such terms are not only useful for referring to those who may be harmed by the system and in what ways, but also for describing assessment and mitigation strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Unbiased? Debiasing? No Such Thing\n",
    "I also want to emphasize that because there are so many different reasons why AI systems can cause fairness-related issues, it is not possible to completely remove bias from a system or guarantee its fairness. As a result, throughout this training you aren't likely to encounter terms like **debiasing** or **unbiased**, as they tend to set unrealistic expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assessing Fairness in Machine Learning\n",
    "\n",
    "The goal of assessing fairness in ML is to answer the questions:\n",
    "* Are there groups of people who are disproportionately, negatively impacted by the system?\n",
    "* If so, in what ways are they impacted and what can we do about it?\n",
    "\n",
    "The steps in AI fairness assessment are:\n",
    "1. Identify potential risks\n",
    "2. Identify the groups that might be impacted\n",
    "3. Quantify the risks\n",
    "4. Compare quantified risks across groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hands on with Fairness Toolkits: A First Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
