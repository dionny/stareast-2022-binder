{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Performance\n",
    "\n",
    "Get ready to put on your mathematics, data science, and ML engineering hats! In the next few lessons, you are going to learn how to evaluate the performance of ML models. Recall that after you train an ML model on past data, you can use that model to make predictions on new or previously unseen data. But how do you know if that model is useful?  In ML, when you hear the phrase \"model performance\", I want you to think about evaluating the quality of model predictions, commonly referred to as its **forecast skill** or **prediction skill**. This first lesson will focus on evaluating predictive modeling in the context of supervised learning, including both classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Classifier Accuracy and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Classification is about predicting a label, typically a discrete value. For example, an image of an animal may be classified as being a picture of a \"cat\" or \"dog\". There are many ways to measure the prediction skill of a classification model, but **accuracy** and **error rate** are the de facto standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy\n",
    "Accuracy is the ratio of the correct predictions to the total number of predictions made.\n",
    "* Accuracy = Correct Predictions / Total Predictions\n",
    "\n",
    "90% and above for the accuracy of a predictive model is considered to be good, and it is common practice to aim for that level. \n",
    "\n",
    "### Error Rate\n",
    "You can also summarize model performance in terms of the error rate.\n",
    "* Error Rate = Incorrect Predictions / Total Predictions\n",
    "\n",
    "Accuracy and error rates are complements of each other and therefore you can calculate one from the other as follows:\n",
    "* Accuracy = 1 - Error Rate\n",
    "* Error Rate = 1 - Accuracy\n",
    "\n",
    "Consider a classifier that labels pictures as either cats or dogs and that, when tested on 12 pictures (8 cats and 4 dogs), produces the following results:\n",
    "* 9 Correct Predictions   = (9/12) = 0.75 \n",
    "* 3 Incorrect Predictions = (3/12) = 0.25\n",
    "\n",
    "Knowing that the classifier has an accuracy of 0.75 or 75%, does not provide any insight into where the classifier is not performing well. \n",
    "\n",
    "Is it more mistaking cats for dogs, or dogs for cats? or is it about the same? \n",
    "\n",
    "This is where a **confusion matrix** may prove useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/confusion_matrix.png\" width=\"200\">\n",
    "\n",
    "A confusion matrix allows you to easily visualize classification performance.  \n",
    "\n",
    "In this confusion matrix, of the 8 cat pictures, the model predicted that 2 were dogs, and of the 4 dog pictures, it predicted that 1 was a cat. All correct predictions are located in the diagonal of the table (highlighted in bold), so it is easy to visually inspect the table for prediction errors, as they are represented by values outside the diagonal. By examining the confusing matrix during development, you can see where the model may be confusing two or more classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hands-On Classification Metrics: First Look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Scikit-learn is a free ML library for the Python programming language. It has 3 different programming interfaces for evaluating the quality of a modelâ€™s predictions:\n",
    "\n",
    "* Estimator Score Method\n",
    "* Scoring Parameter\n",
    "* Metrics Functions\n",
    "\n",
    "In this interactive demonstration, you'll get experience using the scikit-learn metrics functions to measure the prediction skill of a binary classifier that distinguishes cats and dogs. \n",
    "\n",
    "First start by importing the scikit-learn metrics module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Assume that the actual and predicted values from the example are defined as follows, where cats belong to the class 0 and dogs belong to the class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_values = [0,0,0,0,0,0,0,0,1,1,1,1]\n",
    "predictions =   [1,1,0,0,0,0,0,0,1,1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now you can use the metrics functions to calculate the accuracy and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.0 % \n",
      "Confusion Matrix:\n",
      "[[6 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {metrics.accuracy_score(actual_values, predictions) * 100} % ')\n",
    "\n",
    "print(f'Confusion Matrix:')\n",
    "\n",
    "print(metrics.confusion_matrix(actual_values, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifier Precision, Recall, and F-Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As a performance measure, classification accuracy has its limitations. One example where accuracy may be an inadequate performance measure is in the presence of class imbalance. For example, imagine a situation where a dataset of cat and dog images contains a large number of cat examples (majority class) and a small number of dog examples (minority class). On such a dataset, even unskillful models model may achieve high accuracy if the large number of examples from the majority class overwhelms those in the minority class.  \n",
    "\n",
    "An alternative to using classification accuracy is to use precision and recall metrics. \n",
    "\n",
    "However, prior to getting into precision and recall, it is important to dive deeper into the confusion matrix as it provides insight into both the performance of the model and the types of errors being made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion Matrix: Reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/confusion_matrix_reloaded.png\" width=\"200\">\n",
    "\n",
    "The results summary displayed in the confusion matrix consists of true predictions and false predictions.\n",
    "\n",
    "True Predictions: \n",
    "  * TP: True Positives. \n",
    "    - Model predicted Yes, and actual value is Yes.\n",
    "  * TN: True Negatives. \n",
    "    - Model predicted No, and actual value is no.\n",
    "    \n",
    "False Predictions: \n",
    "  * FP: False Positives. \n",
    "    - Model predicted Yes, but actual value is No.\n",
    "  * FN: False Negatives. \n",
    "    - Model predicted No, but actual value is Yes.\n",
    "\n",
    "\n",
    "The **precision** and **recall** metrics are defined using the four terms (TP, TN, FP, and FN) in the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Precision quantifies the number of correct positive predictions made. It answers the question: When the model predicts yes, how often is it right? It is calculated as the ratio of correctly predicted positive examples divided by the total number of positive examples that were predicted.\n",
    "\n",
    "* Precision = True Positives / (True Positives + False Positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Recall quantifies the number of correct positive predictions made out of all of the positive predictions that could have been made. It answers the question: What percentage of the actual positives were identified? Therefore, unlike precision, recall provides an indication of missed positive predictions. It is calculated as the number of true positives divided by the total number of true positives and false negatives.\n",
    "\n",
    "* Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "A predictive model with high recall and low precision returns many results, but most of its predicted labels are incorrect. On the other hand, a predictive model with high precision and low recall returns very few results, but most of its predicted labels are correct. The ideal predictive model has high precision and high recall, returning many results with most of its results labeled correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### F-Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Precision and recall can be used to compute the **F-Measure** &mdash; a single metric that captures both properties. The traditional F measure is calculated as the harmonic mean of the two fractions.\n",
    "\n",
    "* F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "It is sometimes called the **F-Score** or **F1-Score** and is perhaps the most commonly used metric for imbalanced classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hands-On Classification Metrics: Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following code example demonstrates how precision, recall and the f1 score can be computed individually using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score is: 0.6\n",
      "Recall Score is: 0.75\n",
      "F1 Score: 0.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from sklearn import metrics\n",
    "\n",
    "#model prediction results\n",
    "actual_values = [0,0,0,0,0,0,0,0,1,1,1,1]\n",
    "predictions =   [1,1,0,0,0,0,0,0,1,1,1,0]\n",
    "\n",
    "#precision\n",
    "print(f'Precision Score is: {metrics.precision_score(actual_values, predictions)}')\n",
    "\n",
    "#recall\n",
    "print(f'Recall Score is: {metrics.recall_score(actual_values, predictions)}')\n",
    "\n",
    "#f1 score\n",
    "print('F1 Score:', metrics.f1_score(actual_values, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can view a full classification report which includes the accuracy, precision, recall and f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.73      0.75      0.73        12\n",
      "weighted avg       0.77      0.75      0.76        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(metrics.classification_report(actual_values, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 1: Evaluating a Classifier for Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you'll put everything you've learned so far about modeling actual and predicted values, and measuring classification performance in scikit-learn to the test.\n",
    "\n",
    "### Problem Description:\n",
    "You are tasked with evaluating the performance of an predictive ML model for detecting email spam. \n",
    "\n",
    "The model is a binary classifier that distinguishes between email messages that are either **_spam_** or **_not spam_**.\n",
    "\n",
    "### Data:\n",
    "\n",
    "The following table summarizes the performance data for this problem: \n",
    "<table align=\"left\" style=\"border-collapse:collapse;border-spacing:0\" class=\"tg\"><tbody><tr><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\"></td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\"><span style=\"font-weight:bold\">Email 1</span></td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\"><span style=\"font-weight:bold\">Email 2</span></td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 3</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 4</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 5</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 6</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 7</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 8</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 9</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 10</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 11</td><td style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Email 12</td></tr><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Actual Values</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td></tr><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Predictions</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Not Spam<br></td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Spam</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "Use the Python programming language, including the scikit-learn metrics library, to compute the following performance metrics, visualizations, and reports.\n",
    "\n",
    "* Accuracy, Error Rate, Confusion Matrix\n",
    "* Precision, Recall, F1 Score\n",
    "* Tabular Classification Performance Report\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regression Error, Not Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "After learning about predictive classification models, one of the first questions you may have on your mind is: \n",
    "\n",
    ">How do I calculate the accuracy for a regression model? \n",
    ">>The answer here is simple: **you cannot**!\n",
    "\n",
    "Accuracy is a measure of classification, not regression. Questions like the one above are typically a symptom of not understanding the difference between classification and regression, and what accuracy is trying to measure. \n",
    "\n",
    "### Regression vs. Classification\n",
    "Recall that classification is about predicting a discrete class label: _cat_, _dog_, _spam_, _not spam_. In contrast, regression is about predicting a quantity, typically a continuous value such as amounts, sizes, or prices.  For example, consider that a house may be predicted to sell for a specific dollar value.  It only makes sense that if you are predicting a numeric value like this, that you don't want to know if the model predicted the value exactly.  Instead, you care more about how close the prediction was to the expected value. \n",
    "\n",
    "A way to describe the numerical difference between the actual and expected values is **distance** or **error**, and the prediction skill of a regression model is reported as an error in those predictions as opposed to accuracy.\n",
    "\n",
    "### Regression Error Metrics\n",
    "\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/mse.png\" width=\"200\">\n",
    "\n",
    "There are four error metrics that are commonly used for evaluating and reporting on the quality of a regression predictions:\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "* Finds the average squared distance (error) between the predicted and actual values. \n",
    "* Tells you how close a regression line is to a set of points by taking the distances from the points to the line and squaring them.\n",
    "* Squaring removes any (-) negative signs and magnifies large errors. \n",
    "* The lower the MSE, the better the prediction skill.\n",
    "* Formula: \n",
    "  - **MSE** = 1 / N * sum for i to N (y_i â€“ yhat_i)^2\n",
    "\n",
    "#### Root Mean Squared Error (RMSE)\n",
    "\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/rmse.png\" width=\"200\">\n",
    "\n",
    "* Variation of the MSE metric which shows what is the average **deviation** in predictions from actual values.\n",
    "* Follows an assumption that error is unbiased and follows a normal distribution.\n",
    "* Just like MSE, RMSE is a non-negative value and the lower the RMSE, the better the prediction skill.\n",
    "* RMSE punishes large errors and is the best metric for large numbers (actual value or prediction). \n",
    "* It is affected by outliers so make sure that you remove them from the dataset beforehand.\n",
    "* Formula: \n",
    "  - **RMSE** = sqrt(1 / N * sum for i to N (y_i â€“ yhat_i)^2)\n",
    "\n",
    "\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/mae.png\" width=\"270\">\n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "* Computes the average of the absolute error values by forcing the difference between predicted and actual values to be positive.\n",
    "* Unlike the MSE and RMSE that punish larger errors more than smaller errors, the changes in MAE are linear and therefore more intuitive.\n",
    "* MAE gives you information on the magnitude of the error, but no idea of the direction, i.e., Is the model over or under estimating?\n",
    "* Like the others, an error value of 0.0 would be ideal, meaning that all predictions matched the expected values exactly.\n",
    "* Formula: \n",
    "  - **MAE** = 1 / N * sum for i to N abs(y_i â€“ yhat_i)\n",
    "\n",
    "\n",
    "\n",
    "#### R-Squared (R<sup>2</sup>)\n",
    "\n",
    "* Also referred to as the **coefficient of determination**.\n",
    "* Provides an indication of the goodness of fit of a set of predictions to the actual values.\n",
    "* Yields a value between 0 and 1 for no-fit and perfect fit respectively.\n",
    "* Formula: \n",
    "  - **R<sup>2</sup>** = 1 - Unexplained Variance / Total Variance\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"img/rsquared.png\" width=\"500\">\n",
    "\n",
    ">**Calculation**: The actual calculation of R<sup>2</sup> requires several steps, including taking data points (observations) of dependent and independent variables, and finding the line of best fit from a regression model. From there you would calculate predicted values, subtract actual values and, square the results. This yields a list of errors squared, which is then summed and equals the **unexplained variance**.\n",
    "> To calculate the **total variance**, you would subtract the average actual value from each of the actual values, square the results and sum them. From there, divide the first sum of errors (explained variance) by the second sum (total variance), subtract the result from one, and you now have the R-Squared measure.\n",
    "\n",
    ">**Meaning**: R<sup>2</sup> gives you an idea of how many data points fall within the results of the line formed by the regression equation. The higher the coefficient, the higher percentage of points the line passes through when the data points and line are plotted. If the coefficient is 0.80, then 80% of the points should fall within the regression line. Values of 1 or 0 would indicate the regression line represents all or none of the data, respectively. A higher coefficient is an indicator of a better goodness of fit for the observations\n",
    "\n",
    ">**Usefulness**: The usefulness of R<sup>2</sup> is its ability to find the likelihood of future events falling within the predicted outcomes. The idea is that if more samples are added, the coefficient would show the probability of a new point falling on the line. Even if there is a strong connection between the two variables, determination does not prove causality. For example, a study on birthdays may show a large number of birthdays happen within a time frame of one or two months. This does not mean that the passage of time or the change of seasons causes pregnancy.\n",
    "\n",
    "#### Need Help? \n",
    "* If these metrics seem complicated, don't worry... \n",
    "* The good news is that the computing these metrics in Python with open-source libraries is easy\n",
    "* All you have to worry about is knowing:\n",
    "  - The context(s) in which each metric is suitable.\n",
    "  - Any influencing factors or limitations that may impact your evaluation or threaten its validity.\n",
    "  - How to invoke the appropriate metrics functions from your code and interpret the results!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hands-On Regression Metrics: A Quick Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#Load Prediction Results\n",
    "actual_values = [9, -3.3, 6, 11]\n",
    "predictions =   [8.5, -2.9, 6, 9.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.9125000000000005\n",
      "RMSE: 0.9552486587271403\n",
      "MAE:  0.6750000000000002\n",
      "R^2:  0.9696004330897203\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "print (f'MSE:  {metrics.mean_squared_error(actual_values, predictions)}')\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "def rmse(actual_values, predictions):\n",
    "    actual_values = np.asarray(actual_values)\n",
    "    predictions = np.asarray(predictions)\n",
    "    return np.sqrt(((predictions - actual_values) ** 2).mean())\n",
    "print(f'RMSE: {rmse(actual_values, predictions)}')\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "print (f'MAE:  {metrics.mean_absolute_error(actual_values, predictions)}')\n",
    "\n",
    "# Calculate R-Squared\n",
    "print (f'R^2:  {metrics.r2_score(actual_values, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
